
#indices correspond, used to do analysis on saved evaluation_results

exp1_bigchunk = {
    "name": "exp1_bigchunk",
    "path": "results/exp1_bigchunk/",
    "results_path": "evaluation_results/exp1_bigchunk/eval/",
    "explanation": "exp 1 rewards probs",
    "dir_names": ['20230622-212122', '20230622-213421', '20230622-215907', '20230622-221228', '20230622-222745', '20230622-224216', '20230622-225624', '20230622-231138', '20230622-232639', '20230622-234200', '20230622-235653', '20230623-001143', '20230623-002337', '20230623-003528', '20230623-004717', '20230623-005903', '20230623-011053', '20230623-012258', '20230623-013504', '20230623-014707', '20230623-020044', '20230623-021419', '20230623-022715', '20230623-024014', '20230623-025327', '20230623-030638', '20230623-031939', '20230623-033309', '20230623-034620', '20230623-035959', '20230623-041333', '20230623-042700', '20230623-050903', '20230623-052334', '20230623-053840', '20230623-055242', '20230623-060614', '20230623-062011', '20230623-063350', '20230623-064656', '20230623-070029', '20230623-071351', '20230623-072722', '20230623-074144', '20230623-075522', '20230623-080935', '20230623-082327', '20230623-083705', "20230623-091916",
                  "20230623-093309",
                  "20230623-094723",
                  "20230623-100135",
                  "20230623-101601",
                  "20230623-102921",
                  "20230623-104252",
                  "20230623-105519",
                  "20230623-110752",
                  "20230623-112133",
                  "20230623-113431",
                  "20230623-114835",
                  "20230623-124600",
                  "20230623-125955",
                  "20230623-131354",
                  "20230623-132804",
                  "20230623-134111",
                  "20230623-135429",
                  "20230623-140743",
                  "20230623-142041",
                  "20230623-143459",
                  "20230623-144828",
                  "20230623-150149",
                  "20230623-151456",
                  "20230623-152821",
                  "20230623-154116",
                  "20230623-155404",
                  "20230623-160717",
                  "20230623-162040",
                  "20230624-160204",
                  "20230624-161252",
                  "20230624-162345",
                  ],
    "trial_nos": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
                  15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                  27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,
                  39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,
                  51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62,
                  63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80],
    "descriptions": [' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.05', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.05', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.05', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.05', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.05', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.05', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.05', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.05', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.5', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.5', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.5', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.5', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.5', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.5', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.5', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.5', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.7', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.7', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.7', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.7', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.7', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.7', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.7', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.7', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.95', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.95', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.95', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.95', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.95', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.95', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.05', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.05', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.05', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.05', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.5', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.5', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.5', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.5', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.7', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.7', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.7', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.7', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.95', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.95', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.95', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -3 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -3 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -3 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -3 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.3',
                     ' punishment = -3 prize = 20 tiny_prize = 1 traffic_probability 0.05',
                     ' punishment = -3 prize = 20 tiny_prize = 5 traffic_probability 0.05',
                     ' punishment = -3 prize = 30 tiny_prize = 1 traffic_probability 0.05',
                     ' punishment = -3 prize = 30 tiny_prize = 5 traffic_probability 0.05',
                     ' punishment = -3 prize = 20 tiny_prize = 1 traffic_probability 0.5',
                     ' punishment = -3 prize = 20 tiny_prize = 5 traffic_probability 0.5',
                     ' punishment = -3 prize = 30 tiny_prize = 1 traffic_probability 0.5',
                     ' punishment = -3 prize = 30 tiny_prize = 5 traffic_probability 0.5',
                     ' punishment = -3 prize = 20 tiny_prize = 1 traffic_probability 0.7',
                     ' punishment = -3 prize = 20 tiny_prize = 5 traffic_probability 0.7',
                     ' punishment = -3 prize = 30 tiny_prize = 1 traffic_probability 0.7',
                     ' punishment = -3 prize = 30 tiny_prize = 5 traffic_probability 0.7',
                     ' punishment = -3 prize = 20 tiny_prize = 1 traffic_probability 0.95', ' punishment = -3 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -3 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -3 prize = 30 tiny_prize = 1 traffic_probability 0.95'],
    "traffic_probabilities" : [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.95, 0.95, 0.95, 0.95, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.05, 0.05, 0.05, 0.05, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.95, 0.95, 0.95, 0.95],
    # every list above this line correspond in indices
    "test_arrays": {  # note they are not necessarily in this order, this is just to give the numbers
        "traffic_probability_list": [0.05, 0.3, 0.5, 0.7, 0.95], # add 0.3
        "prize_list": [20, 30],
        "tiny_prize_list": [1, 5],
        "punishment_list": [-1, -3, -5, -10],
    },
    "irl_v":["Results", "value_it_irl"],
    "expert_v":["Cognitive Calculations", "value_it_1_and_2_soph_subj_all"],
    "opt_v": ["Results", "optimal_det_policy"],
    "impossible_states": [5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 78, 81, 82, 83, 85, 86, 87, 88],
    "actions": [(1, 0), (-1, 0), (0, 1), (0, -1)],
    "n_states": 100,
    "late_dir_names": ["late20230624-212935",
"late20230624-214319",
"late20230624-215639",
"late20230624-220934",
"late20230624-222130"]
    }
#
# print(len(exp1_bigchunk["dir_names"]))
# print(len(exp1_bigchunk["trial_nos"]))
# print(len(exp1_bigchunk["descriptions"]))
# print(len(exp1_bigchunk["traffic_probabilities"]))

# added even later
# 0.3 for probability
# [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]
#[' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.3']
#[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]


'''
results_dict = {
            "cosine_sim_dict": {
                "avg_sim_irl_exp": avg_sim_irl_exp,
                "avg_sim_irl_opt": avg_sim_irl_opt,
                "avg_sim_exp_opt": avg_sim_exp_opt,
            },
            "rewards_dict": {
                "rewards_expert": np.round(rewards_expert, 2),
                "r1_expert": np.round(r1_expert, 2),
                "r2_expert": np.round(r2_expert, 2),
                "rewards_irl": np.round(rewards_irl, 2),
                "r1_irl": np.round(r1_irl, 2),
                "r2_irl": np.round(r2_irl, 2),
                "rewards_optimal": np.round(rewards_optimal, 2),
                "r1_optimal": np.round(r1_optimal, 2),
                "r2_optimal": np.round(r2_optimal, 2)
            },
            "expert_st_policy": expert_policy,
            "expert_trajectories": expert_trajectory_states,
            "agent_st_policy": agent_policy,
            "agent_trajectories": agent_trajectory_states,
            "value_it_irl": value_it_irl,
            "optimal_st_policy": optimal_st_policy,
            "optimal_det_policy": optimal_det_policy,
            "optimal_trajectories": optimal_trajectory_states,
            "reward_maxent": reward_maxent,
            "e_svf": e_svf,
            "e_features": e_features,
            "trajectory_feature_expectation": e_features,
            "maxent_feature_expectation": features.T.dot(e_svf),
        }
'''