
#indices correspond, used to do analysis on saved results

exp1_bigchunk = {
    "name": "exp1_bigchunk",
    "path": "results/exp1_bigchunk/",
    "explanation": "exp 1 rewards probs",
    "dir_names": ['20230622-212122', '20230622-213421', '20230622-215907', '20230622-221228', '20230622-222745', '20230622-224216', '20230622-225624', '20230622-231138', '20230622-232639', '20230622-234200', '20230622-235653', '20230623-001143', '20230623-002337', '20230623-003528', '20230623-004717', '20230623-005903', '20230623-011053', '20230623-012258', '20230623-013504', '20230623-014707', '20230623-020044', '20230623-021419', '20230623-022715', '20230623-024014', '20230623-025327', '20230623-030638', '20230623-031939', '20230623-033309', '20230623-034620', '20230623-035959', '20230623-041333', '20230623-042700', '20230623-050903', '20230623-052334', '20230623-053840', '20230623-055242', '20230623-060614', '20230623-062011', '20230623-063350', '20230623-064656', '20230623-070029', '20230623-071351', '20230623-072722', '20230623-074144', '20230623-075522', '20230623-080935', '20230623-082327', '20230623-083705', "20230623-091916"],
    "trial_nos": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64],
    "descriptions": [' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.05', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.05', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.05', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.05', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.05', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.05', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.05', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.05', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.5', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.5', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.5', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.5', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.5', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.5', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.5', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.5', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.7', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.7', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.7', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.7', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.7', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.7', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.7', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.7', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.95', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.95', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.95', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.95', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.95', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.95', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.05', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.05', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.05', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.05', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.5', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.5', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.5', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.5', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.7', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.7', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.7', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.7', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.95', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.95', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.95', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.95', ' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -3 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -3 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -3 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -3 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.3'],
    "traffic_probabilities" :[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.95, 0.95, 0.95, 0.95, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],
    # every list above this line correspond in indices
    "test_arrays": {  # note they are not necessarily in this order, this is just to give the numbers
        "traffic_probability_list": [0.05, 0.3, 0.5, 0.7, 0.95], # add 0.3
        "prize_list": [20, 30],
        "tiny_prize_list": [1, 5],
        "punishment_list": [-1, -3, -5, -10],
    },
    "irl":["Results", "value_it_irl"],
    "expert":["Cognitive Calculations", "value_it_1_and_2_soph_subj_all"],
    "opt": ["Results", "optimal_det_policy"]

    }


# added even later
# 0.3 for probability
# [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]
#[' punishment = -1 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -1 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -5 prize = 30 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 20 tiny_prize = 5 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 1 traffic_probability 0.3', ' punishment = -10 prize = 30 tiny_prize = 5 traffic_probability 0.3']
#[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]


'''
results_dict = {
            "cosine_sim_dict": {
                "avg_sim_irl_exp": avg_sim_irl_exp,
                "avg_sim_irl_opt": avg_sim_irl_opt,
                "avg_sim_exp_opt": avg_sim_exp_opt,
            },
            "rewards_dict": {
                "rewards_expert": np.round(rewards_expert, 2),
                "r1_expert": np.round(r1_expert, 2),
                "r2_expert": np.round(r2_expert, 2),
                "rewards_irl": np.round(rewards_irl, 2),
                "r1_irl": np.round(r1_irl, 2),
                "r2_irl": np.round(r2_irl, 2),
                "rewards_optimal": np.round(rewards_optimal, 2),
                "r1_optimal": np.round(r1_optimal, 2),
                "r2_optimal": np.round(r2_optimal, 2)
            },
            "expert_st_policy": expert_policy,
            "expert_trajectories": expert_trajectory_states,
            "agent_st_policy": agent_policy,
            "agent_trajectories": agent_trajectory_states,
            "value_it_irl": value_it_irl,
            "optimal_st_policy": optimal_st_policy,
            "optimal_det_policy": optimal_det_policy,
            "optimal_trajectories": optimal_trajectory_states,
            "reward_maxent": reward_maxent,
            "e_svf": e_svf,
            "e_features": e_features,
            "trajectory_feature_expectation": e_features,
            "maxent_feature_expectation": features.T.dot(e_svf),
        }
'''