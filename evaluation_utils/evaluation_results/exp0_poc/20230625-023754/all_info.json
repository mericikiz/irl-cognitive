{"Experiment info": {"exp name": "poc world with different cognitive params", "RL algorithm used": "Value Iteration", "what is being tested": "cog params:  alpha 0.3 beta 1.0 kappa 1.0 eta 1.0 cc_constant 1.0 baseline 0.0 time_disc_1 0.8 time_disc_2 0.8", "mode": "subjective", "trial no": 506, "cognitive distortion": 0.98}, "Cognitive parameters": {"cognitive_control": 1.0, "time_disc_1": 0.8, "time_disc_2": 0.8, "alpha": 0.3, "beta": 1.0, "kappa": 1.0, "eta": 1.0, "baseline": 0.0, "baseline_changes": false}, "Other parameters": {"policy weighting": "        new_other_params = defaults.get_other_params_dict(policy_weighting= lambda x: x**30) #rest is default values\n", "number of expert trajectories": 50, "eliminate loops in trajectory": true}, "Environment": {"deterministic": false, "width": 5, "height": 5, "traffic_probability": 0.5, "punishment": -5, "prize": 30, "tiny_prize": 2, "very_tiny_prize": 1.0, "start": [10], "terminal": [24, 4], "semi target": [4], "places_list": ["home", "bank", "agent"], "start_states": [10], "terminal_states": [24, 4], "traffic": {"indices": [3, 8, 12, 13, 14], "p": 0.5, "r1": -5, "r2": 0}, "home": {"indices": [24], "r1": 2, "p": 1.0, "r2": 2}, "bank": {"indices": [4], "r1": 2, "p": 1.0, "r2": 30}, "agent": {"indices": [10], "r1": 0, "r2": 0}, "roads": {"vertical": [], "horizontal": [], "road_length": 0}}, "Extra": {"n_states": 25, "num road cells": 0, "ratio of usable states": 0.0, "sum_r1": -8.5, "sum_r2": 32.0, "sum_positive_rewards": 36.0, "sum_negative_rewards": -12.5, "sum_r": 23.5, "simple_rp_1": [0.0, 0.0, 0.0, -2.5, 2.0, 0.0, 0.0, 0.0, -2.5, 0.0, 0.0, 0.0, -2.5, -2.5, -2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0]}, "Results": {"cosine_sim_dict": {"avg_sim_irl_exp": 0.96, "avg_sim_irl_opt": 0.87, "avg_sim_exp_opt": 0.89}, "rewards_dict": {"rewards_expert": 28.7, "r1_expert": -1.3, "r2_expert": 30.0, "rewards_irl": 28.35, "r1_irl": -1.65, "r2_irl": 30.0, "rewards_optimal": 28.95, "r1_optimal": -1.05, "r2_optimal": 30.0}, "expert_st_policy": [[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.998, 0.001, 0.001, 0.0], [0.461, 0.001, 0.0, 0.539], [0.5, 0.0, 0.0, 0.5], [0.53, 0.0, 0.0, 0.47], [0.5, 0.0, 0.0, 0.5], [0.001, 0.0, 0.0, 0.999], [0.439, 0.001, 0.0, 0.561], [0.439, 0.0, 0.0, 0.561], [0.364, 0.0, 0.0, 0.636], [0.5, 0.0, 0.0, 0.5], [0.001, 0.0, 0.0, 0.999], [0.404, 0.001, 0.0, 0.596], [0.366, 0.0, 0.0, 0.634], [0.366, 0.0, 0.0, 0.634], [0.404, 0.0, 0.0, 0.596], [0.0, 0.0, 0.0, 1.0], [0.694, 0.001, 0.0, 0.305], [0.695, 0.0, 0.0, 0.305], [0.727, 0.0, 0.0, 0.273], [0.727, 0.0, 0.0, 0.273], [0.0, 0.0, 0.0, 1.0]], "expert_trajectories": [[10, 11, 6, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 6, 7, 8, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 12, 7, 8, 3, 4], [10, 5, 6, 7, 8, 9, 4], [10, 11, 6, 7, 8, 9, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 11, 12, 7, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 12, 13, 8, 3, 4], [10, 5, 6, 7, 8, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 6, 7, 8, 13, 14, 9, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 12, 13, 14, 9, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 7, 8, 3, 4], [10, 11, 12, 13, 8, 9, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 6, 7, 8, 9, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 7, 8, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4]], "agent_st_policy": [[0.938, 0.0, 0.062, 0.0], [0.911, 0.034, 0.055, 0.0], [0.911, 0.046, 0.043, 0.0], [0.88, 0.064, 0.056, 0.0], [0.662, 0.209, 0.129, 0.0], [0.525, 0.124, 0.027, 0.324], [0.454, 0.032, 0.03, 0.484], [0.442, 0.031, 0.019, 0.509], [0.363, 0.028, 0.024, 0.586], [0.151, 0.049, 0.029, 0.771], [0.421, 0.1, 0.028, 0.452], [0.356, 0.03, 0.031, 0.583], [0.439, 0.033, 0.022, 0.506], [0.357, 0.025, 0.026, 0.593], [0.15, 0.051, 0.03, 0.769], [0.433, 0.115, 0.033, 0.418], [0.367, 0.037, 0.037, 0.559], [0.471, 0.041, 0.027, 0.461], [0.351, 0.029, 0.029, 0.591], [0.153, 0.055, 0.034, 0.759], [0.437, 0.126, 0.0, 0.437], [0.385, 0.044, 0.0, 0.572], [0.476, 0.047, 0.0, 0.476], [0.366, 0.035, 0.0, 0.599], [0.0, 0.077, 0.0, 0.923]], "agent_trajectories": [[10, 5, 6, 1, 2, 3, 4], [10, 11, 16, 17, 12, 7, 2, 3, 4], [10, 11, 6, 7, 8, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 12, 7, 2, 3, 4], [10, 5, 6, 7, 2, 3, 8, 13, 14, 9, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 7, 8, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 6, 7, 2, 3, 8, 9, 4], [10, 11, 12, 13, 8, 9, 4], [10, 5, 6, 7, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 15, 16, 11, 6, 1, 2, 3, 4], [10, 11, 12, 7, 8, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 15, 16, 11, 6, 7, 8, 9, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 6, 7, 8, 3, 4], [10, 11, 12, 7, 2, 3, 4], [10, 11, 12, 7, 6, 1, 2, 3, 4], [10, 11, 12, 7, 2, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 8, 9, 4], [10, 5, 6, 1, 2, 7, 8, 13, 18, 19, 14, 9, 4], [10, 15, 16, 11, 6, 7, 2, 3, 4], [10, 11, 6, 7, 8, 9, 4], [10, 5, 6, 7, 8, 9, 4], [10, 5, 6, 7, 2, 3, 4], [10, 5, 6, 7, 8, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 11, 6, 7, 8, 3, 4], [10, 5, 0, 1, 2, 7, 8, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 8, 9, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4]], "value_it_irl": [19.055, 20.209, 21.263, 22.325, 23.201, 18.457, 19.365, 20.166, 21.163, 21.971, 17.55, 18.412, 19.049, 20.071, 20.807, 16.812, 17.57, 18.156, 19.063, 19.726, 16.13, 16.812, 17.34, 18.156, 18.752], "optimal_st_policy": [[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.998, 0.001, 0.001, 0.0], [0.499, 0.001, 0.001, 0.499], [0.5, 0.0, 0.0, 0.5], [0.466, 0.0, 0.0, 0.534], [0.63, 0.0, 0.0, 0.37], [0.001, 0.0, 0.0, 0.999], [0.25, 0.25, 0.25, 0.25], [0.256, 0.001, 0.0, 0.743], [0.271, 0.0, 0.0, 0.729], [0.5, 0.0, 0.0, 0.5], [0.001, 0.0, 0.0, 0.999], [0.0, 0.333, 0.333, 0.333], [0.304, 0.348, 0.0, 0.348], [0.718, 0.0, 0.0, 0.282], [0.702, 0.0, 0.0, 0.298], [0.001, 0.0, 0.0, 0.999], [0.001, 0.5, 0.0, 0.5], [0.026, 0.973, 0.0, 0.001], [0.961, 0.0, 0.0, 0.039], [0.961, 0.0, 0.0, 0.039], [0.0, 0.0, 0.0, 1.0]], "optimal_det_policy": [0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], "optimal_trajectories": [[10, 15, 16, 17, 18, 19, 14, 9, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 7, 8, 9, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 6, 7, 8, 9, 4], [10, 11, 12, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 12, 7, 8, 9, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 6, 7, 8, 9, 4], [10, 11, 6, 7, 2, 3, 4], [10, 11, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 6, 7, 8, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 6, 7, 8, 9, 4], [10, 11, 12, 7, 2, 3, 4], [10, 11, 6, 1, 2, 3, 8, 9, 4], [10, 11, 6, 7, 8, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4], [10, 11, 12, 13, 14, 9, 4], [10, 11, 6, 1, 2, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 5, 6, 1, 2, 3, 4], [10, 11, 6, 7, 8, 9, 4], [10, 5, 6, 1, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 5, 6, 7, 8, 3, 4], [10, 11, 12, 13, 8, 9, 4], [10, 5, 6, 7, 2, 3, 4], [10, 5, 6, 7, 2, 3, 4], [10, 5, 0, 1, 2, 3, 4], [10, 11, 6, 1, 2, 3, 4]], "reward_maxent": [0.868, 1.073, 1.171, 1.445, 2.321, 1.029, 1.178, 1.031, 1.071, 1.091, 0.94, 0.985, 0.9, 1.026, 1.034, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "e_svf": [0.205, 0.466, 0.731, 0.89, 0.614, 0.464, 0.618, 0.465, 0.275, 0.096, 1.026, 0.549, 0.219, 0.081, 0.018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "e_features": [0.24, 0.58, 0.76, 0.88, 1.0, 0.48, 0.66, 0.36, 0.22, 0.12, 1.0, 0.52, 0.1, 0.08, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "trajectory_feature_expectation": [0.24, 0.58, 0.76, 0.88, 1.0, 0.48, 0.66, 0.36, 0.22, 0.12, 1.0, 0.52, 0.1, 0.08, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "maxent_feature_expectation": [0.205, 0.466, 0.731, 0.89, 0.614, 0.464, 0.618, 0.465, 0.275, 0.096, 1.026, 0.549, 0.219, 0.081, 0.018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "Cognitive Calculations": {"cognitive_distortion": 0.98, "reward_arr1_o": [0.0, 0.0, 0.0, -5.0, 2.0, 0.0, 0.0, 0.0, -5.0, 0.0, 0.0, 0.0, -5.0, -5.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "reward_arr2_o": [0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "simple_p1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "simple_rp_1": [0.0, 0.0, 0.0, -2.5, 2.0, 0.0, 0.0, 0.0, -2.5, 0.0, 0.0, 0.0, -2.5, -2.5, -2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "simple_r": [0.0, 0.0, 0.0, -2.5, 32.0, 0.0, 0.0, 0.0, -2.5, 0.0, 0.0, 0.0, -2.5, -2.5, -2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], "v2_o": [61.437, 76.797, 95.997, 119.997, 149.997, 49.149, 61.437, 76.797, 95.997, 119.997, 39.318, 49.149, 61.437, 76.797, 95.997, 31.454, 39.318, 49.149, 61.437, 76.797, 25.982, 32.478, 40.598, 50.749, 63.437], "v1_o": [0.995, 1.244, 1.555, 1.944, 5.555, 1.164, 1.455, 1.244, 1.055, 4.444, 1.455, 1.82, -0.225, 0.344, 1.055, 1.82, 2.275, 2.844, 3.555, 4.444, 2.275, 2.844, 3.555, 4.444, 5.555], "simple_v": [35.768, 44.71, 55.888, 69.86, 88.888, 28.614, 35.768, 44.71, 55.638, 71.111, 28.614, 28.614, 34.518, 43.261, 55.639, 28.614, 22.892, 28.487, 35.609, 44.511, 28.614, 22.891, 25.349, 31.687, 39.609], "subjective": {"r1_subj_r": [-0.0, -0.0, -0.0, -5.0, 1.231, -0.0, -0.0, -0.0, -5.0, -0.0, -0.0, -0.0, -5.0, -5.0, -5.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.231], "r1_subj_p": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "r1_subj_all": [-0.0, -0.0, -0.0, -2.5, 1.231, -0.0, -0.0, -0.0, -2.5, -0.0, -0.0, -0.0, -2.5, -2.5, -2.5, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.231], "v1_subj_v": [0.572, 0.716, 0.573, 0.236, 3.42, 0.716, 0.895, 0.716, -0.312, 2.736, 0.895, 1.12, -1.1, -0.75, -0.311, 1.12, 1.4, 1.75, 2.188, 2.736, 1.4, 1.75, 2.188, 2.736, 3.42], "v1_comb_subj_all": [1.241, 1.552, 1.94, 2.425, 6.156, 0.993, 1.241, 1.552, 1.44, 4.925, 0.794, 0.993, -1.259, -1.348, 1.44, 0.636, 0.794, 0.737, 0.921, 1.152, 0.882, 1.102, 1.378, 1.722, 2.153], "v2_comb_subj_all": [61.44, 76.8, 96.0, 120.0, 150.0, 49.152, 61.44, 76.8, 96.0, 120.0, 39.322, 49.152, 61.44, 76.8, 96.0, 31.457, 39.322, 49.152, 61.44, 76.8, 25.985, 32.481, 40.602, 50.752, 63.44], "value_it_1_and_2_soph_subj_all": [62.109, 77.636, 97.367, 122.189, 152.736, 49.429, 61.786, 77.635, 97.751, 122.189, 39.221, 49.025, 61.281, 76.201, 97.751, 30.973, 38.716, 48.139, 60.173, 75.216, 25.467, 31.833, 39.791, 49.738, 62.173]}, "objective": {}}}